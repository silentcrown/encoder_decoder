{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "from data import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  loading:  ../ATIS_dataset-master/data/raw_data/ms-cntk-atis/atis.train.pkl\n",
      "      samples: 4978\n",
      "   vocab_size:  943\n",
      "   slot count:  129\n",
      " intent count:   26\n",
      "Done  loading:  ../ATIS_dataset-master/data/raw_data/ms-cntk-atis/atis.test.pkl\n",
      "      samples:  893\n",
      "   vocab_size:  943\n",
      "   slot count:  129\n",
      " intent count:   26\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "train, test, dic = load_processed_data()\n",
    "query, slots, intent = train\n",
    "test_query, test_slots, test_intent = test\n",
    "term2ind, slot2ind, intent2ind, ind2term, ind2slot, ind2intent = dic \n",
    "ind2term[len(ind2term)] = 'null'\n",
    "term2ind['null'] = len(ind2term) - 1\n",
    "ind2slot[len(ind2slot)] = '<start>'\n",
    "slot2ind['<start>'] = len(ind2slot) - 1\n",
    "ind2slot[len(ind2slot)] = '<end>'\n",
    "slot2ind['<end>'] = len(ind2slot) - 1\n",
    "ind2slot[len(ind2slot)] = '#'\n",
    "slot2ind['#'] = len(ind2slot) - 1\n",
    "train_length = np.array([len(query[i]) for i in range(len(query))])\n",
    "test_length = np.array([len(test_query[i]) for i in range(len(test_query))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for i in range(len(query)):\n",
    "    temp = []\n",
    "    for j in range(query[i].shape[0]):\n",
    "        temp.append(query[i][j])\n",
    "    while len(temp) < 50:\n",
    "        temp.append(term2ind['null'])\n",
    "    train_x.append(temp[:50])\n",
    "test_x = []\n",
    "for i in range(len(test_query)):\n",
    "    temp = []\n",
    "    for j in range(test_query[i].shape[0]):\n",
    "        temp.append(test_query[i][j])\n",
    "    while len(temp) < 50:\n",
    "        temp.append(term2ind['null'])\n",
    "    test_x.append(temp[:50])\n",
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)\n",
    "train_y_slots = []\n",
    "for i in range(len(slots)):\n",
    "    #temp = [slot2ind['<start>']]\n",
    "    temp = []\n",
    "    for j in range(slots[i].shape[0]):\n",
    "        temp.append(slots[i][j])\n",
    "    #temp.append(slot2ind['<end>'])\n",
    "    while len(temp) < 50:\n",
    "        temp.append(slot2ind['#'])\n",
    "    train_y_slots.append(temp[:50])    \n",
    "test_y_slots = []\n",
    "for i in range(len(test_slots)):\n",
    "    temp = []\n",
    "    #temp = [slot2ind['<start>']]\n",
    "    for j in range(test_slots[i].shape[0]):\n",
    "        temp.append(test_slots[i][j])\n",
    "    #temp.append(slot2ind['<end>'])\n",
    "    while len(temp) < 50:\n",
    "        temp.append(slot2ind['#'])\n",
    "    test_y_slots.append(temp[:50])  \n",
    "train_y_slots = np.array(train_y_slots)\n",
    "test_y_slots = np.array(test_y_slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=50):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) #\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,criterion, max_length = 50):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    decoder_input = torch.tensor([[slot2ind['<start>']]])\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == slot2ind['<end>']:\n",
    "            break\n",
    "\n",
    "                \n",
    "                \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(data, encoder, decoder, n_iters, print_every=1000, plot_every=1000, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adagrad(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adagrad(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [random.choice(data) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = torch.from_numpy(training_pair[0])\n",
    "        target_tensor = torch.from_numpy(training_pair[1])\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    print(plot_losses)\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(len(ind2term), hidden_size)\n",
    "decoder1 = AttnDecoderRNN(hidden_size, len(ind2slot))\n",
    "trainset = [(train_x[i],train_y_slots[i]) for i in range(len(train_y_slots))]\n",
    "testset = [(test_x[i], test_y_slots[i]) for i in range(len(test_y_slots))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6m 14s (- 24m 58s) (1000 20%) 0.4816\n",
      "12m 28s (- 18m 42s) (2000 40%) 0.3757\n",
      "18m 39s (- 12m 26s) (3000 60%) 0.3474\n",
      "24m 42s (- 6m 10s) (4000 80%) 0.3311\n",
      "31m 0s (- 0m 0s) (5000 100%) 0.3145\n",
      "[0.48156593373298734, 0.37568732307910885, 0.3474396129798888, 0.3310674879550934, 0.3145484156656268]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHNJJREFUeJzt3XlwVdeB5/Hv0YqEhIQWkIwkniQWIYTsYJBBYCdOcIwNBib2pGJ32sGk46mZdk87M5VUPGW84SlPu7sSzySpSScxjrM6bo8D2IbCdntJMIvZbCN2LUggARIPtCGElnfmj/csE8wiQHrnLb9PlaokvQv3VxfeT1fn3HuusdYiIiKRJcZ1ABERGXoqdxGRCKRyFxGJQCp3EZEIpHIXEYlAKncRkQikchcRiUAqdxGRCKRyFxGJQHGudpyVlWU9Ho+r3YuIhKXt27efsNZmX247Z+Xu8XjYtm2bq92LiIQlY0z9YLbTsIyISARSuYuIRCCVu4hIBFK5i4hEIJW7iEgEUrmLiEQglbuISAQKu3Lfeugk//e9GtcxRERCWtiV+7pdx3h2/T4+OtzqOoqISMgKu3L/7m0TyU5J5NFVu+j36eHeIiIXEnblnjoinkcXllLV2M7vtwzqLlwRkagTduUOcFd5LnMmZPLs+v20dJx1HUdEJOSEZbkbY3hqcRndvf08s26v6zgiIiEnLMsdoDg7he/cXMSrOxrZUut1HUdEJKSEbbkD/MOXJzIuPYnlq6vo7fe5jiMiEjLCutyTEmJ5/K5SDhzv5IUP6lzHEREJGWFd7gC3lY7lKyVjeO7tgxxtO+M6johISAj7cjfG8MSiqfT7LCte3+M6johISAj7cgfIz0jmoVsnsHbXMf58oMV1HBER5yKi3AEe/GIRhVkjeWx1Fd29/a7jiIg4FTHlnhgXy5OLpnLI28XP/1zrOo6IiFMRU+4At0zKZsG0XH76bjUN3i7XcUREnImocgd4dOEUYmMMT7y2G2u1sJiIRKeIK/fctCS+O28S7+xr5q09x13HERFxIuLKHWDpHA+Txqbw5Gt76Orpcx1HRCToIrLc42NjeHrJNBpbz/CTd6pdxxERCbqILHeAisIMvjZ9HL/4Sy3VzZ2u44iIBFXEljvAI3dMISk+lsdWV2lyVUSiSkSXe3ZqIt+7fTIba7y89slR13FERIImossd4L6bxjNtXBpPv76Hju5e13FERIIi4ss9Nsbw9JIyWjrP8qO3DrqOIyISFBFf7gDX56dzb0UBv9pYx56mdtdxRESGXVSUO8D3b59MenICy1dX4fNpclVEIlvUlHt6cgI/uKOE7fWneGX7EddxRESGVdSUO8A90/OYMX40z6zby6nTPa7jiIgMm6gq95gYw4olZbR39/Hs+v2u44iIDJuoKneAKbmjWFrp4aWtDXx0uNV1HBGRYRF15Q7w8LyJZKck8uiqXfRrclVEIlBUlnvqiHiWLyylqrGd322pdx1HRGTIRWW5Aywsz2XuhCz+ef1+WjrOuo4jIjKkorbcjTE8uXgq3b39PLN2r+s4IiJDKmrLHaA4O4UHbyni1Z2NbK71uo4jIjJkorrcAR66dSLj0pN4bHUVvf0+13FERIZE1Jd7UkIsTyyayoHjnbzwQZ3rOCIiQyLqyx3gttKxfKVkDM+9fZCjbWdcxxERuWYq94AnFk2l32dZ8foe11FERK6Zyj0gPyOZh26dwNpdx3j/QIvrOCIi10Tlfo4Hv1hEYdZIHl9dRXdvv+s4IiJXTeV+jsS4WJ5aPJVD3i5+/uda13FERK6ayv08N0/MZsG0XH76bjUN3i7XcURErorK/QKWLywlLsbw+JoqrNXCYiISflTuF5CTNoKH503i3f0tvLnnuOs4IiJXTOV+EUvneJg8NpWnXttDV0+f6zgiIldE5X4R8bExrFhSRmPrGX7yTrXrOCIiV0TlfgkVhRncPT2PX/yllurmTtdxREQGTeV+GY/cWUJSfCyPrdbkqoiED5X7ZWSlJPK9+SVsrPGy5uMm13FERAZF5T4I91UUUJ6XxtNv7KW9u9d1HBGRy1K5D0JsjGHF4jJOdJ7lR28dcB1HROSyVO6DdH1+OvdVFPDixkPsbmpzHUdE5JJU7lfge7dPJj05geWrqvD5NLkqIqFL5X4F0pMTeOSOEnY0tPLK9iOu44iIXJTK/QrdPT2PGeNH88y6vZw63eM6jojIBancr1BMjGHFkjLau/t4dv1+13FERC5I5X4VpuSOYmmlh5e2NrCz4ZTrOCIin6Nyv0oPz5vImNRElq+uol+TqyISYlTuVyl1RDyPLiilqrGd322pdx1HROSvqNyvwcLyXOZOyOKf1++npeOs6zgiIgNU7tfAGMOTi6fS3dvPM2v3uo4jIjJA5X6NirNTePCWIl7d2cjmWq/rOCIigMp9SDx060TGpSfx2Ooqevt9ruOIiKjch0JSQixPLJrKgeOdvPBBnes4IiIq96FyW+lY5k0Zw3NvH+Ro2xnXcUQkyqnch9Djd02l32dZ8foe11FEJMqp3IdQfkYy//DlCazddYz3D7S4jiMiUUzlPsS+c0sRRVkjeXx1Fd29/a7jiEiUUrkPscS4WJ5cPJVD3i7+9f1a13FEJEqp3IfBzROzWVCey0/fq6bee9p1HBGJQir3YbJ8QSnxMYYn1uzGWi0sJiLBpXIfJjlpI/jubZN4d38Lb+457jqOiEQZlfsw+lalh8ljU3nqtT109fS5jiMiUUTlPoziY2N4+j+U0dh6hh+/U+06johEEZX7MJvpyeDu6Xn88i+1VDd3uI4jIlFC5R4Ej9xZQlJ8LMtXaXJVRIJD5R4EWSmJfG9+CZtqvaz5uMl1HBGJAir3ILmvooDyvDSefmMv7d29ruOISIRTuQdJbIzh6SVlnOg8y4/eOuA6johEOJV7EJXnpXNfRQEvbjzE7qY213FEJIKp3IPs+7eXMDo5geWrqvD5NLkqIsND5R5kacnx/OCOEnY0tPLK9iOu44hIhFK5O3D39DxmekbzzLq9nDrd4zqOiEQglbsDMTGGFUvKaO/u49n1+13HEZEIpHJ3pCRnFA9UenhpawM7G065jiMiEUbl7tDDt01iTGoij66qol+TqyIyhFTuDqUkxrF8YSm7m9r57eZ613FEJIKo3B1bMC2XuROy+Jc399Pc0e06johECJW7Y8YYnlw8le7efp5Zu891HBGJECr3EFCcncJ/uqWYP+1sZHOt13UcEYkAKvcQ8fe3TmBcehLLV1XR2+9zHUdEwpzKPUQkJcTy5KKpHGzuZOWGOtdxRCTMqdxDyLzSscybMob//e8HaWo94zqOiISxQZW7MWa+MWa/MabaGPODS2x3tzHGGmNmDF3E6PL4XVPxWcuK1/e4jiIiYeyy5W6MiQV+CtwBlAL3GmNKL7BdKvCPwJahDhlN8jOSeejWCayrOsZ7+5tdxxGRMDWYM/cKoNpaW2ut7QFeAhZfYLsVwD8Bulj7Gn3nliKKskby+JrddPf2u44jImFoMOU+Djh8ztdHAt8bYIyZDuRba98YwmxRKzEulqcWl1Hv7eJf3691HUdEwtA1T6gaY2KAHwL/fRDbPmiM2WaM2dbS0nKtu45ocydmsaA8l5++V02997TrOCISZgZT7o1A/jlf5wW+96lUoAx4zxhzCJgFrLnQpKq19ufW2hnW2hnZ2dlXnzpKLF9QSnyM4Yk1u7FWC4uJyOANpty3AhONMYXGmATgG8CaT1+01rZZa7OstR5rrQfYDCyy1m4blsRRJCdtBN+9bRLv7m/hzT3HXccRkTBy2XK31vYBDwHrgb3Ay9ba3caYp4wxi4Y7YLT7VqWHkpxUnlyzm66ePtdxRCRMDGrM3Vq71lo7yVpbbK39n4HvPWatXXOBbb+ks/ahEx8bw4olZTS1dfPjd6pdxxGRMKE7VMPATE8G99yYxy/+XEt1c4frOCISBlTuYeIHd5SQnBDL8lWaXBWRy1O5h4mslES+P7+ETbVe1nzc5DqOiIQ4lXsYubeigPK8NJ5+Yy/t3b2u44hICFO5h5HYGMPTS8o40XmWH755wHUcEQlhKvcwU56Xzt/cVMCvNx1id1Ob6zgiEqJU7mHoe18tYXRyAstXVeHzaXJVRD5P5R6G0pLjeeTOKexoaOXfth++/B8Qkaijcg9Td08fx0zPaP7Xun2cOt3jOo6IhBiVe5gyxrBiSRnt3X08u36f6zgiEmJU7mGsJGcUD1R6eGnrYXY0nHIdR0RCiMo9zD182yTGpCayfFUV/ZpcFZEAlXuYS0mMY/nCUnY3tfPbzfWu44hIiFC5R4AF03K5eWIW/7J+P80deoStiKjcI4IxhicXTeVsn49n1mpyVURU7hGjKDuFB28p4k87G9lc63UdR0QcU7lHkL+/dQJ5o5NYvqqK3n6f6zgi4pDKPYIkJcTyxF1TOdjcycoNda7jiIhDKvcIM690LPOmjOW5tw/S1HrGdRwRcUTlHoEev6sUi2XF63tcRxERR1TuESg/I5l/+PJE1lUd4739za7jiIgDKvcI9Xc3F1KUNZLH1+ymu7ffdRwRCTKVe4RKjIvlqcVl1Hu7+Nn7Na7jiEiQqdwj2NyJWSwsz+W5tw9y/8oPeW9/M9Zq/RmRaBDnOoAMr3+6u5ySnFR+vamepS9sZcKYFB6Y4+FrX8gjKSHWdTwRGSbG1ZncjBkz7LZt25zsOxr19Pl4Y1cTz2+oo6qxnfTkeO6rKOD+2R5y0ka4jicig2SM2W6tnXHZ7VTu0cVay9ZDp3h+Qy1v7jlOrDEsKM9l2ZxCrs9Pdx1PRC5jsOWuYZkoY4yhojCDisIMGrxdvLjpEH/cepjVHzUxY/xovj23kNtKxxIXq+kYkXCmM3eho7uXl7cd4Vcb6zh88gzj0pN4YI6Hr8/MZ9SIeNfxROQcGpaRK9bvs7y15zgrP6jjw7qTjEyI5T/OyOeBOR7GZ450HU9EULnLNapqbGPlhjpe+6SJPp9l3pSxLJtTyKyiDIwxruOJRC2VuwyJ5vZufrO5nt9taeDk6R5Kc0exbG4hd12fS2KcLqUUCTaVuwyp7t5+Vu1sZOUHdRw43klWSiJ/O2s8fzOrgKyURNfxRKKGyl2GhbWWDdUnWLmhjnf3t5AQF8OSG65j2dxCSnJGuY4nEvF0KaQMC2MMN0/M5uaJ2VQ3d/KrjXW8sv0IL287wpwJmSybU8itk8cQE6NxeRGXdOYu16y1q4c/fHiYFzce4lh7N4VZI3lgjoe7p+cxMlHnDyJDScMyEnS9/T7WVR3j+Q11fHy4lVEj4ri3ooD7Kz2MS09yHU8kIqjcxRlrLTsaWlm5oY51VUcxxjC/LIdvzy1kesFo1/FEwprG3MUZYww3jh/NjeNHc+RUF7/ZVM/vP2zgjU+OckN+Ot+eW8j8shzitcSByLDRmbsExemzfbyy/QgvfFDHIW8XuWkj+Falh3tnFpCWrCUORAZLwzISknw+yzv7mln5QR0ba7wkxcdyz415LJ3joTg7xXU8kZCncpeQt/doOys31LH6oyZ6+n18uWQMy+YUMmdCppY4ELkIlbuEjZaOs/xuSz2/3VzPic4eJo9NZdlcD4tvGMeIeC1xIHIulbuEnbN9/az5yP+0qH3HOsgYmcA3byrgm7PHMyZVT4sSAZW7hDFrLZtqvazcUMe/72smLsZw1/XXsWxOIWXj0lzHE3FKl0JK2DLGUFmcRWVxFnUnTvPixkO8vO0wr+5o5KbCDJbNLWTelLHEaokDkYvSmbuEhbYzvby89TC/2niIxtYzFGQks7TS/7SoFC1xIFFEwzISkfr6fby55zjPb6hje/0pUhPj+PrMfJZWesjPSHYdT2TYqdwl4n102L/EwdpdR/FZy1dLc/j2zYXMGD9al1JKxFK5S9Q42naGX2+q5/dbGmg700t5XhrL5hRy57RcEuK0xIFEFpW7RJ2unj5e3eF/WlRty2nGjkrk/tke7q0oIGNkgut4IkNC5S5Ry+ezvH+whZUb6vjLwRMkxsXwtel5LJvjYeLYVNfxRK6JLoWUqBUTY7h18hhunTyGA8c7eOGDOl7dcYQ/fNjALZOyWTbHwxcnZWtcXiKaztwlKng7z/KHDxv49aZ6mjvOMmFMCg/M8fC1L+SRlKAlDiR8aFhG5AJ6+ny8scu/xEFVYzvpyfHcV1HA/bM95KRpiQMJfSp3kUuw1rL10Cme31DLm3uOE2sMC8pzWTankOvz013HE7kojbmLXIIxhorCDCoKM2jwdvHipkP8cethVn/UxA356XxpcjazizK5oSCdxDgN20j40Zm7SEBHdy//tu0Ir+48wu6mdqyFEfExzBifweziTGYVZVKel6bHA4pTGpYRuQZtXb1sqfOyscbL5lov+451ADAyIZaZhRnMLspkdnEmU69L0wJmElQalhG5BmnJ8Xx1ag5fnZoD+K+22VJ3kk01XjbWnOC9/S0ApI6I46bCDGYXZzG7KJOSnFRiVPYSAlTuIoOQmZLIndNyuXNaLgDN7d1sqvWf1W+q8fL23mYARifHc1Oh/6y+sjiTCWNSdD29OKFhGZEh0NR6hk01XjYFyr6x9QwAWSmJzCryj9nPLsqkMGukyl6uicbcRRw6fLJrYAhnU62X4+1nAcgZNWKg6GcXZ2qZYrliGnMXcSg/I5n8jGS+PjMfay11J06zqdY/QfuXgy38aWcjAOPSk6gs9hf97OJMctOSHCeXSKEzd5Egs9ZysLnTP4xT42VznZfWrl4APJnJgaLPYlZRhh4MLp+jYRmRMOHzWfYea/cXfa2XLbUn6TjbB8CEMSkDQzizijK1dLGo3EXCVV+/j91N7QOTs1sPnaSrpx+AkpzUgTH7m4oySUuKd5xWgk3lLhIhevt9fHKkjc21/gnabYdOcbbPhzFQdl3aQNnPLMzQw8KjgMpdJEKd7evno4bWgTP7nQ2t9PT7iI0xTBuXNjBBO2N8hpYzjkAqd5Eo0d3bz/b6UwPX2X98uJU+nyU+1nBDfjqzizKZVZzJ9ILRjIhX2Yc7lbtIlDp9to+th07676Ct8bKrsQ2fhYS4GG4sGD1w2eX1eel6gHgYUrmLCADt3b18WHtyYBhn7zH/ipdJ8bHM8IweGLOfNi6NOK14GfJU7iJyQa1dPWyuPcmmwN2zB453ApCSGEfFOSteTskdpRUvQ5DuUBWRC0pPTmB+WQ7zy/wrXp7oPDuwANqmWi/v7PMvgjZqRBw3FWUOTNBOGqMVL8OJyl0kymWlJLKw/DoWll8HwPH27oG7ZzfVenlrz3EAMkYm+BdBC5zZF2drxctQpmEZEbmkI6e6Bop+c42XprZuALJTEweKvrI4k4KMZJV9EGjMXUSGnLWWhpNdbDznzL6lw7/i5bj0pIHJ2coJWgRtuKjcRWTYWWupaen8q7XsTwUWQSvMGvlXyxtnpSQ6ThsZVO4iEnQ+n2XfsQ421pz43CJok8emDlxjP6swk7RkrYtzNVTuIuJcX7+PqqZ2/0NLAougdfd+ti5OZbH/7tkKTwYjtS7OoKjcRSTknO3r5+PDbWysOcHGGi8fBdbFiYsxXJ+fPnDZpZZKuDiVu4iEvDM9/nVxPi37XY1t9PvswFIJlcX+ydnyvHTidfcsoHIXkTDU0d3L1kMn2VjtfyThnqPtACQnxDLTk+Ev++IsSq+L3rtnVe4iEvZOne5hS52/6DfWeKlu9i+VcO7ds5XFWUwaGz03VGn5AREJe6NHJjC/LJf5ZbkANLd3D1xyubHms7tnM0cmMKv4s7L3ZOqGKp25i0jYOnyya+DO2Q9qTnC83X9DVW7aiM/unp2Qxbj0yLmhSmfuIhLx8jOSyc9I5usz8rHWUnfitP/u2Vov7x1o4dWdjQCMz0weKPvZxZmMSR3hOPnw05m7iEQkn89yoLmDjdWBdXFqvXR0+2+omjgmZWBNnFlFmaQnJzhOO3iaUBUROUe/z7K7qW1gXZwP605yprcfY6A0d9TAmjgzPRmkjgjdu2dV7iIil9DT5+OTI62BK3FOsKOhlZ4+/4PGy/MCDxovyuLG8aND6kHjKncRkSvQ3dvPjvpTA2X/8ZHADVWxMXyhIJ3K4ixmF2dyQ77bZ8+q3EVErkHnpw8aD5T97qa/fvbsp2Vfdt2ooD57VuUuIjKEWrt62FL3Wdl/+uzZ1MQ4birKYHZxFrOLMinJGd7HEepSSBGRIZSenMDtU3O4far/2bMtHf5nz/onaE/w9l7/s2dHJ8cHLrnMorI4k6KskU5uqNKZu4jIEGhqPTNw5+ymmhMDjyMck5o4cOfs7OJM8jOSr2k/GpYREXHEWku913/37Kdlf6KzB4C80Uk8e085lcVZV/V3a1hGRMQRYwyerJF4skZyb0UB1loONncOjNfnjBr+O2RV7iIiw8wYw6SxqUwam8q3Kj1B2adWvxcRiUAqdxGRCKRyFxGJQCp3EZEIpHIXEYlAKncRkQikchcRiUAqdxGRCORs+QFjTAtQf5V/PAs4MYRxhopyXRnlujLKdWVCNRdcW7bx1trsy23krNyvhTFm22DWVgg25boyynVllOvKhGouCE42DcuIiEQglbuISAQK13L/uesAF6FcV0a5roxyXZlQzQVByBaWY+4iInJp4XrmLiIilxDS5W6MmW+M2W+MqTbG/OACrycaY/4YeH2LMcYTIrmWGmNajDEfBT7+LgiZVhpjmo0xVRd53Rhj/k8g8yfGmOnDnWmQub5kjGk751g9FqRc+caYd40xe4wxu40x/3iBbYJ+zAaZK+jHzBgzwhjzoTHm40CuJy+wTdDfj4PMFfT34zn7jjXG7DTGvH6B14b3eFlrQ/IDiAVqgCIgAfgYKD1vm/8C/Czw+TeAP4ZIrqXAT4J8vG4BpgNVF3n9TmAdYIBZwJYQyfUl4HUH/79ygemBz1OBAxf4dwz6MRtkrqAfs8AxSAl8Hg9sAWadt42L9+NgcgX9/XjOvv8b8PsL/XsN9/EK5TP3CqDaWltrre0BXgIWn7fNYuDFwOevAF8xw/+Y8cHkCjpr7Z+Bk5fYZDHwa+u3GUg3xuSGQC4nrLVHrbU7Ap93AHuBcedtFvRjNshcQRc4Bp2BL+MDH+dP2AX9/TjIXE4YY/KABcAvL7LJsB6vUC73ccDhc74+wuf/kw9sY63tA9qAzBDIBXB34Ff5V4wx+cOcaTAGm9uF2YFfq9cZY6YGe+eBX4e/gP+s71xOj9klcoGDYxYYYvgIaAbestZe9HgF8f04mFzg5v34HPB9wHeR14f1eIVyuYez1wCPtbYceIvPfjrL5+3Afzv19cCPgVXB3LkxJgX4f8DD1tr2YO77Ui6Ty8kxs9b2W2tvAPKACmNMWTD2ezmDyBX096MxZiHQbK3dPtz7uphQLvdG4NyfsHmB711wG2NMHJAGeF3nstZ6rbVnA1/+ErhxmDMNxmCOZ9BZa9s//bXaWrsWiDfGZAVj38aYePwF+jtr7asX2MTJMbtcLpfHLLDPVuBdYP55L7l4P142l6P34xxgkTHmEP6h2y8bY3573jbDerxCudy3AhONMYXGmAT8Ew5rzttmDfCtwOf3AO/YwOyEy1znjcsuwj9u6toa4P7AFSCzgDZr7VHXoYwxOZ+OMxpjKvD/nxz2Qgjs83lgr7X2hxfZLOjHbDC5XBwzY0y2MSY98HkScBuw77zNgv5+HEwuF+9Ha+0j1to8a60Hf0e8Y6395nmbDevxihuqv2ioWWv7jDEPAevxX6Gy0lq72xjzFLDNWrsG/5vgN8aYavyTdt8IkVz/1RizCOgL5Fo63LmMMX/AfxVFljHmCPA4/sklrLU/A9biv/qjGugCHhjuTIPMdQ/wn40xfcAZ4BtB+AEN/jOrvwV2BcZrAf4HUHBONhfHbDC5XByzXOBFY0ws/h8mL1trX3f9fhxkrqC/Hy8mmMdLd6iKiESgUB6WERGRq6RyFxGJQCp3EZEIpHIXEYlAKncRkQikchcRiUAqdxGRCKRyFxGJQP8f+8H2sixTsQQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainIters(trainset, encoder1, decoder1, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, encoder, decoder, sentence, max_length=50):\n",
    "    with torch.no_grad():\n",
    "        #input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_tensor = torch.from_numpy(data)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[slot2ind['<start>']]])  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoded_indexes = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == slot2ind['<end>']:\n",
    "                #decoded_words.append('<end>')\n",
    "                decoded_indexes.append(slot2ind['<end>'])\n",
    "                break\n",
    "            else:\n",
    "                decoded_indexes.append(topi.item())\n",
    "                #decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_indexes,decoder_attentions[:di + 1] #decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(pairs, encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(pair[0], encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(map(str,output_words))\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [178 549 827 200 925 429 851 662 444 351 179 943 943 943 943 943 943 943\n",
      " 943 943 943 943 943 943 943 943 943 943 943 943 943 943 943 943 943 943\n",
      " 943 943 943 943 943 943 943 943 943 943 943 943 943 943]\n",
      "= [128 128 128 128 128 128 128 128 128  17 128 131 131 131 131 131 131 131\n",
      " 131 131 131 131 131 131 131 131 131 131 131 131 131 131 131 131 131 131\n",
      " 131 131 131 131 131 131 131 131 131 131 131 131 131 131]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c98c86ad7412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluateRandomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-d33dd89ef54d>\u001b[0m in \u001b[0;36mevaluateRandomly\u001b[0;34m(pairs, encoder, decoder, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(testset, encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:yxvenv]",
   "language": "python",
   "name": "conda-env-yxvenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
